{
  "vocab_size": 30522,
  "d_model": 768,
  "position_signal": "relative_attention_bias",
  "num_blocks": 12,
  "block_layers": ["attention", "feedforward"],
  "layer_output_dropout_prob": 0.1,
  "residual_structure": "direct",
  "use_bias": false,
  "attention_num_heads": 12,
  "attention_head_size": 64,
  "attention_probs_dropout_prob": 0.1,
  "feedforward_intermediate_size": 3072,
  "feedforward_intermediate_act": "relu",
  "feedforward_intermediate_dropout_prob": 0.0,
  "type_vocab_size": 2,
  "initializer_range": null
}
